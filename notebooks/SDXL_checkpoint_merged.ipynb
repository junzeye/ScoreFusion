{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. To reproduce images provided in our submission, the ideal runtime enviornment for this Jupyter notebook is Google Colab using an A100 GPU.\n",
    "2. You may need a Hugging Face account to download the LoRA adapters, but registeration is free.\n",
    "3. If you run into an issue with insufficient GPU memory (which might happen if you use an L4 GPU instead of A100), try decreasing the size of a batch to 1 or 2.\n",
    "4. Make sure to configure the working directory of your jupyter notebook as the project root directory (NOT the `notebooks` folder) to avoid importing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load necessary packages\n",
    "# %%capture\n",
    "# !pip install accelerate diffusers transformers\n",
    "# !pip install -U peft\n",
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the available cuda devices\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "PROFESSION = 'mathematics scientist'\n",
    "positive_prompt = f\"a photo of a {PROFESSION}, looking at the camera, ultra quality, sharp focus\"\n",
    "negative_prompt = \"cartoon, anime, 3d, painting, b&w, low quality\"\n",
    "adapters = [\"white_male\", \"asian_female\"]\n",
    "\n",
    "model_dict = {\n",
    "    \"asian_female\": \"NYUAD-ComNets/Asian_Female_Profession_Model\",\n",
    "    \"white_male\": \"NYUAD-ComNets/White_Male_Profession_Model\"\n",
    "}\n",
    "models = [model_dict[name] for name in adapters]\n",
    "pipeline = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", variant=\"fp16\", use_safetensors=True, torch_dtype=torch.float16).to(\"cuda\")\n",
    "for i,j in zip(models,adapters):\n",
    "    pipeline.load_lora_weights(i, weight_name=\"pytorch_lora_weights.safetensors\",adapter_name=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_adapters(adapters, adapter_weights=[0.5, 0.5]) # merge the two LoRA checkpoints\n",
    "\n",
    "TOTAL_SIZE, NUM_BATCHES = 32, 4\n",
    "\n",
    "generator = torch.Generator(device=\"cuda\")\n",
    "generator.manual_seed(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "all_images = []\n",
    "for i in range(NUM_BATCHES):\n",
    "    generator.manual_seed(i)\n",
    "    all_images += pipeline(\n",
    "        prompt=positive_prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps = 100,\n",
    "        num_images_per_prompt = int(TOTAL_SIZE / NUM_BATCHES),\n",
    "        generator = generator,\n",
    "        height = 1024,\n",
    "        width = 1024\n",
    "    ).images\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(16, 16))\n",
    "for ax, img in zip(axs.flatten(), all_images[:16]):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
